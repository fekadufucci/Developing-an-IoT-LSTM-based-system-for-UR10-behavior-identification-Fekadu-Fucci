import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import pickle
# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)
# Load the dataset
df = pd.read_csv("reduced_dataset.csv")
# Ensure the target column exists
if 'ur10_behaviour' not in df.columns:
    raise ValueError("The 'ur10_behaviour' column is missing in the dataset.")
# Data preprocessing
def preprocess_data(df):
    # Select features and target
    features = df.drop(columns=['ur10_behaviour']).values
    target = df['ur10_behaviour'].values
    # Normalize features
    scaler = MinMaxScaler()
    features_scaled = scaler.fit_transform(features)
    return features_scaled, target, scaler
# Create sequences with overlapping windows
def create_sequences(data, target, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(target[i + seq_length])
    return np.array(X), np.array(y)
# Build LSTM model
def build_model(input_shape):
    model = Sequential([
        LSTM(2, return_sequences=False, activation='tanh', input_shape=input_shape),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.0005),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model
# Plot training history
def plot_training_history(history):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    # Loss plot
    ax1.plot(history.history['loss'], label='Training Loss')
    ax1.plot(history.history['val_loss'], label='Validation Loss')
    ax1.set_title('Model Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    # Accuracy plot
    ax2.plot(history.history['accuracy'], label='Training Accuracy')
    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax2.set_title('Model Accuracy')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.legend()
    plt.tight_layout()
    plt.show()
# Plot confusion matrix
def plot_confusion_matrix(y_test, y_pred):
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()
def main():
    # Preprocess data
    features_scaled, target, scaler = preprocess_data(df)
    # Save the scaler for later use in deployment
    with open('scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    print("Scaler saved as 'scaler.pkl'.")
    # Create sequences
    seq_length = 10
    X, y = create_sequences(features_scaled, target, seq_length)
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.35, random_state=42, shuffle=False
    )
    # Define callbacks
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=30,
            restore_best_weights=True,
            verbose=1
        ),
        ModelCheckpoint(
            'lstm_model.keras',
            monitor='val_loss',
            save_best_only=True,
            verbose=1
        )
    ]
    # Build and train model
    model = build_model((X_train.shape[1], X_train.shape[2]))
    history = model.fit(
        X_train, y_train,
        epochs=500,
        batch_size=30,
        validation_split=0.4,
        callbacks=callbacks,
        verbose=1
    )
    # Plot training history
    plot_training_history(history)
    # Make predictions
    y_pred = (model.predict(X_test) > 0.5).astype(int)
    # Plot confusion matrix
    plot_confusion_matrix(y_test, y_pred)
if __name__ == "__main__":
    main()
